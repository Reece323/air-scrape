{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyGOoQK--suC"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUlWioQ_Ewh6",
        "outputId": "67894a5a-c3fb-471c-b660-3e03900477b1"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade category_encoders rich catboost\n",
        "from rich.console import Console\n",
        "console = Console()\n",
        "print = console.print\n",
        "from wrangling import X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLSNojRdJs6T"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import yellowbrick as yb\n",
        "from yellowbrick.features import Rank1D\n",
        "from yellowbrick.regressor import AlphaSelection, PredictionError, ResidualsPlot\n",
        "from yellowbrick.datasets import load_energy\n",
        "from yellowbrick.model_selection import ValidationCurve\n",
        "from yellowbrick.style import set_palette\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lars\n",
        "from sklearn.linear_model import TheilSenRegressor\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "from sklearn.linear_model import PassiveAggressiveRegressor\n",
        "from sklearn.linear_model import ARDRegression\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.svm import NuSVR\n",
        "from sklearn.svm import LinearSVR\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "import lightgbm as lgb\n",
        "import catboost as ctb\n",
        "\n",
        "from hyperopt import STATUS_OK, STATUS_FAIL, Trials, fmin, hp, tpe\n",
        "\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1Rn66CNE-6O"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.30,random_state=21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w43TfvAhFHlt"
      },
      "outputs": [],
      "source": [
        "plt.style.context('dark_background')\n",
        "set_palette('sns_bright')\n",
        "\n",
        "cm = sns.color_palette(\"blend:white,#00ff77\", as_cmap=True)\n",
        "\n",
        "def headd(i):\n",
        "    return i.style.background_gradient(cmap = cm,axis=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nma7g9uF-ysz"
      },
      "source": [
        "### Visuals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EU66xZbjJs6Y",
        "outputId": "4d38e901-4705-4cc9-f764-745fa650b67d"
      },
      "outputs": [],
      "source": [
        "## Ranking the features\n",
        "\n",
        "fig, ax = plt.subplots(1, figsize=(10, 35))\n",
        "vzr = Rank1D(ax=ax, color='#00ff77')\n",
        "vzr.fit(X_train, y_train)\n",
        "vzr.transform(X_train)\n",
        "sns.despine(left=True, bottom=True)\n",
        "vzr.poof();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "W7mx-z2GJs6Z",
        "outputId": "555047c9-e4ab-4e6b-e55c-9b65de43eaf1"
      },
      "outputs": [],
      "source": [
        "# Showing the Residuals, differences between observed and predicted values of data \n",
        "# the 'delta' between the actual target value and the fitted value. Residual is a crucial concept in regression problems\n",
        "\n",
        "model = Ridge()\n",
        "visualizer = ResidualsPlot(\n",
        "    model,\n",
        "    hist=False,\n",
        "    qqplot=True,\n",
        "    size=(600, 200),\n",
        "    train_color=\"indigo\",\n",
        "    test_color=\"#00ff77\", \n",
        "    )\n",
        "\n",
        "visualizer.fit(X_train, y_train)\n",
        "visualizer.score(X_test, y_test)\n",
        "# visualizer.score(X_test, y_test)\n",
        "g = visualizer.poof();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heARyAA8Js6e"
      },
      "outputs": [],
      "source": [
        "X_outliers = pd.DataFrame(index=X.columns, columns=['outliers', 'outliers%'])\n",
        "\n",
        "for col in X.columns:\n",
        "    if any(x in str(X[col].dtype)for x in ['int', 'float', 'int64', 'uint8']):\n",
        "        \n",
        "        X_outliers.loc[col, 'count'] = len(X)\n",
        "        X_outliers.loc[col, 'q1'] = X[col].quantile(0.25)\n",
        "        X_outliers.loc[col, 'q3'] = X[col].quantile(0.75)\n",
        "        X_outliers.loc[col, 'iqr'] = X_outliers.loc[col, 'q3'] - X_outliers.loc[col, 'q1']\n",
        "        X_outliers.loc[col, 'lower'] = X_outliers.loc[col, 'q1'] - (3 * X_outliers.loc[col, 'iqr'])\n",
        "        X_outliers.loc[col, 'upper'] = X_outliers.loc[col, 'q3'] + (3 * X_outliers.loc[col, 'iqr'])\n",
        "        X_outliers.loc[col, 'min'] = X[col].min()\n",
        "        X_outliers.loc[col, 'max'] = X[col].max()\n",
        "        X_outliers.loc[col, 'outliers'] = ((X[col] < X_outliers.loc[col, 'lower']) | (X[col] > X_outliers.loc[col,'upper'])).sum()\n",
        "        X_outliers.loc[col, 'outliers%'] = np.round(X_outliers.loc[col,\n",
        "        'outliers'] / len(X) *100)\n",
        "        \n",
        "# headd(X_outliers.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "BKB22tafJs6e",
        "outputId": "50416e1e-668f-441a-93fa-9c15c1d2ee2c"
      },
      "outputs": [],
      "source": [
        "#Distribution of price\n",
        "%matplotlib inline\n",
        "\n",
        "fig, axs = plt.subplots(ncols=2, figsize=(14, 4))\n",
        "fig.suptitle('Distribution of max guests (before and after removing large listings > 10)', weight='bold', fontsize=12)\n",
        "\n",
        "# Before cleaning\n",
        "x_axis=X['numberOfGuests'].dropna()\n",
        "sns.distplot(pd.Series(x_axis, name='Max guests (before cleaning)'), ax=axs[0])\n",
        "\n",
        "# Remove where price > 1000\n",
        "condition = X[X['numberOfGuests'] > 400]\n",
        "rows_to_drop = condition.index\n",
        "print(\"You dropped {} rows.\".format(condition.shape[0]))\n",
        "X = X.drop(rows_to_drop, axis=0)\n",
        "print(\"Dataset has {} rows, {} columns.\".format(*X.shape))\n",
        "\n",
        "#After cleaning\n",
        "x_axis=X['numberOfGuests'].dropna()\n",
        "sns.distplot(pd.Series(x_axis, name='Max guests (after cleaning)'), ax=axs[1]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "WZ0itckqJs6g",
        "outputId": "1237d067-e439-4ab4-d368-f82790cef1aa"
      },
      "outputs": [],
      "source": [
        "## Adding est. Annual Revenue\n",
        "print(\"Dataset has {} rows, {}  before engineering.\".format(*X.shape))\n",
        "avg_occupancy_per_week = 4\n",
        "X['yield'] = avg_occupancy_per_week * y  * 52\n",
        "\n",
        "# cols_to_drop = ['cleaning_fee']\n",
        "# df = df.drop(cols_to_drop, axis = 1)\n",
        "print(\"Dataset has {} rows, {} columns.\".format(*X.shape))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcqG7v8NJs6g"
      },
      "source": [
        "### Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxPmK_cRJs6m"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atqlHUSEe4Bv",
        "outputId": "66672bd4-63a7-4267-f341-98b06a106a25"
      },
      "outputs": [],
      "source": [
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTPBjLF9e3-2"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "kKXfW3dJe361",
        "outputId": "7dfed357-3bc6-48ef-e01f-10402eed6832"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(y_pred, y_test, edgecolors=(0, 0, 1))\n",
        "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('Actual')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "1Rp1jaYDe333",
        "outputId": "5c27c024-3091-4a64-a849-60d9c9c27a74"
      },
      "outputs": [],
      "source": [
        "# model evaluation for testing set\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = math.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(\"The model performance for testing set\")\n",
        "print(\"--------------------------------------\")\n",
        "print('MAE:  {}'.format(round(mae)))\n",
        "print('MSE:  {}'.format(round(mse)))\n",
        "print('RMSE: {}'.format(round(rmse)))\n",
        "print('R2:   {}'.format(round(r2, 3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZefHH09-luZ"
      },
      "source": [
        "### Multiple Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fi1QQb2SJs6m"
      },
      "outputs": [],
      "source": [
        "regressors = {\n",
        "    \"XGBRegressor\": XGBRegressor(),\n",
        "    \"RandomForestRegressor\": RandomForestRegressor(),\n",
        "    \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n",
        "    \"SVR\": SVR(),\n",
        "    \"NuSVR\": NuSVR(),\n",
        "    \"LinearSVR\": LinearSVR(),\n",
        "    \"KernelRidge\": KernelRidge(),\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "    \"Ridge\":Ridge(),\n",
        "    \"HuberRegressor\": HuberRegressor(),\n",
        "    \"PassiveAggressiveRegressor\": PassiveAggressiveRegressor(),\n",
        "    \"ARDRegression\": ARDRegression(),\n",
        "    \"BayesianRidge\": BayesianRidge(),\n",
        "    \"ElasticNet\": ElasticNet(),\n",
        "    \"OrthogonalMatchingPursuit\": OrthogonalMatchingPursuit(),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "zF_M6WxwJs6n",
        "outputId": "842901e9-a5e8-4213-812e-e400ff05d569"
      },
      "outputs": [],
      "source": [
        "df_models = pd.DataFrame(columns=['Model', 'Run_Time', 'MAE', 'MSE', 'R2', 'RMSE', 'RMSE_CV'])\n",
        "\n",
        "for key in regressors:\n",
        "\n",
        "    print('✓',key)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    regressor = regressors[key]\n",
        "\n",
        "    model = regressor.fit(X_train, y_train)\n",
        "    \n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    scores = cross_val_score(model, \n",
        "                             X_train, \n",
        "                             y_train,\n",
        "                             scoring=\"neg_mean_squared_error\", \n",
        "                             cv=10)\n",
        "\n",
        "    row = {'Model': key,\n",
        "           'Run_Time': format(round((time.time() - start_time)/60,2)),\n",
        "           'MAE': round(mean_absolute_error(y_test, y_pred)),\n",
        "           'MSE': round(mean_squared_error(y_test, y_pred)),\n",
        "           'R2': round(r2_score(y_test, y_pred), 3),\n",
        "           'RMSE': round(np.sqrt(mean_squared_error(y_test, y_pred))),\n",
        "           'RMSE_CV': round(np.mean(np.sqrt(-scores)))\n",
        "    }\n",
        "    \n",
        "    df_models = df_models.append(row, ignore_index=True)\n",
        "    df_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "B9zocN1kJs6n",
        "outputId": "461125d9-7ef7-4476-b323-918b39462a27"
      },
      "outputs": [],
      "source": [
        "df_models.sort_values(by='RMSE_CV', ascending=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OXm4TVoAaVn"
      },
      "source": [
        "### Focusing on XGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "732unYm890tJ"
      },
      "outputs": [],
      "source": [
        "hyperparameter_grid = {\n",
        "    'n_estimators': [100],\n",
        "    'max_depth': [2, 3, 5],\n",
        "    'learning_rate': [.001,.01]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs7QgrkR90pR",
        "outputId": "5cd4ce34-3bde-40fc-debd-7482524f1398"
      },
      "outputs": [],
      "source": [
        "random_cv = RandomizedSearchCV(\n",
        "    estimator=XGBRegressor(),\n",
        "    param_distributions=hyperparameter_grid,\n",
        "    cv=3,\n",
        "    n_iter=30,\n",
        "    scoring = 'neg_mean_absolute_error',\n",
        "    n_jobs = -1,\n",
        "    verbose = 5, \n",
        "    return_train_score = True,\n",
        "    random_state=13\n",
        "    )\n",
        "\n",
        "random_cv.fit(X_train,y_train)\n",
        "\n",
        "random_cv.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNe0l3lf90mZ"
      },
      "outputs": [],
      "source": [
        "regressor = random_cv.best_estimator_\n",
        "regressor.fit(X_train,y_train)\n",
        "y_pred = regressor.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "6NrRXFFv90gY",
        "outputId": "96f4d181-87b3-4925-bca4-41d0c271dd27"
      },
      "outputs": [],
      "source": [
        "# model evaluation for testing set\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = math.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"The model performance for testing set\")\n",
        "print(\"--------------------------------------\")\n",
        "print('MAE:  {}'.format(round(mae)))\n",
        "print('MSE:  {}'.format(round(mse)))\n",
        "print('RMSE: {}'.format(round(rmse)))\n",
        "print('R2:   {}'.format(round(r2, 3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "3L6zff0b90dc",
        "outputId": "54909bb2-ed81-4fd8-f9d5-79b13a9bf4a9"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({'Actual': y_test, 'Predicted': np.around(y_pred)})\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go7B4mQxRV6i"
      },
      "source": [
        "### XGB with DMatrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HWAqI4IoXC0"
      },
      "outputs": [],
      "source": [
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "0q0FyYKZx6Mz",
        "outputId": "4b7e2874-4c51-4e73-a1a8-d2abe7b4ea52"
      },
      "outputs": [],
      "source": [
        "mean_train = np.mean(y_train)\n",
        "baseline_predictions = np.ones(y_test.shape) * mean_train\n",
        "mae_baseline = mean_absolute_error(y_test, baseline_predictions)\n",
        "print(\"Baseline MAE: {:.2f}\".format(mae_baseline))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BSi4CtCyrmG"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'max_depth':6,\n",
        "    'min_child_weight': 1,\n",
        "    'eta':.3,\n",
        "    'subsample': 1,\n",
        "    'colsample_bytree': 1,\n",
        "    'objective':'reg:squarederror',\n",
        "}\n",
        "\n",
        "\n",
        "params['eval_metric'] = \"mae\"\n",
        "num_boost_round = 999\n",
        "\n",
        "model = xgb.train(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=num_boost_round,\n",
        "    evals=[(dtest, \"Test\")],\n",
        "    early_stopping_rounds=10,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "U3FGqzFNzB0d",
        "outputId": "fef18911-34ff-40c8-bc27-69bfbb044b15"
      },
      "outputs": [],
      "source": [
        "cv_results = xgb.cv(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=num_boost_round,\n",
        "    seed=42,\n",
        "    nfold=5,\n",
        "    metrics={'mae'},\n",
        "    early_stopping_rounds=10\n",
        ")\n",
        "cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "q0bG7EuVzMef",
        "outputId": "f33b749f-06ec-4296-9cac-cff6efdacf78"
      },
      "outputs": [],
      "source": [
        "print(f'CV-MAE: {round(cv_results[\"test-mae-mean\"].min())}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpXrNAfEzSt_"
      },
      "outputs": [],
      "source": [
        "gridsearch_params = [\n",
        "    (max_depth, min_child_weight)\n",
        "    for max_depth in range(9,12)\n",
        "    for min_child_weight in range(5,8)\n",
        "]\n",
        "\n",
        "min_mae = float(\"Inf\")\n",
        "\n",
        "best_params = None\n",
        "\n",
        "for max_depth, min_child_weight in gridsearch_params:\n",
        "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
        "                             max_depth,\n",
        "                             min_child_weight))    # Update our parameters\n",
        "    params['max_depth'] = max_depth\n",
        "    params['min_child_weight'] = min_child_weight    # Run CV\n",
        "    cv_results = xgb.cv(\n",
        "        params,\n",
        "        dtrain,\n",
        "        num_boost_round=num_boost_round,\n",
        "        seed=42,\n",
        "        nfold=5,\n",
        "        metrics={'mae'},\n",
        "        early_stopping_rounds=10,\n",
        "    )\n",
        "    mean_mae = cv_results['test-mae-mean'].min()\n",
        "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
        "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
        "    if mean_mae < min_mae:\n",
        "        min_mae = mean_mae\n",
        "        best_params = (max_depth,min_child_weight)\n",
        "\n",
        "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "473pBbi8zqob"
      },
      "outputs": [],
      "source": [
        "params['max_depth'] = 9\n",
        "params['min_child_weight'] = 5\n",
        "\n",
        "gridsearch_params = [\n",
        "    (subsample, colsample)\n",
        "    for subsample in [i/10. for i in range(7,11)]\n",
        "    for colsample in [i/10. for i in range(7,11)]\n",
        "]\n",
        "\n",
        "min_mae = float(\"Inf\")\n",
        "best_params = None# We start by the largest values and go down to the smallest\n",
        "for subsample, colsample in reversed(gridsearch_params):\n",
        "    print(\"CV with subsample={}, colsample={}\".format(\n",
        "                             subsample,\n",
        "                             colsample))    # We update our parameters\n",
        "    params['subsample'] = subsample\n",
        "    params['colsample_bytree'] = colsample    # Run CV\n",
        "    cv_results = xgb.cv(\n",
        "        params,\n",
        "        dtrain,\n",
        "        num_boost_round=num_boost_round,\n",
        "        seed=42,\n",
        "        nfold=5,\n",
        "        metrics={'mae'},\n",
        "        early_stopping_rounds=10\n",
        "    )    # Update best score\n",
        "    mean_mae = cv_results['test-mae-mean'].min()\n",
        "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
        "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
        "    if mean_mae < min_mae:\n",
        "        min_mae = mean_mae\n",
        "        best_params = (subsample,colsample)\n",
        "        \n",
        "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NATS6omP1PGO"
      },
      "outputs": [],
      "source": [
        "%time\n",
        "\n",
        "params['subsample'] = 1\n",
        "params['colsample_bytree'] = 1\n",
        "\n",
        "min_mae = float(\"Inf\")\n",
        "best_params = None\n",
        "\n",
        "for eta in [.3, .2, .1, .05, .01, .005]:\n",
        "    print(\"CV with eta={}\".format(eta))    # We update our parameters\n",
        "    params['eta'] = eta\n",
        "    cv_results = xgb.cv(\n",
        "        params,\n",
        "        dtrain,\n",
        "        num_boost_round=num_boost_round,\n",
        "        seed=42,\n",
        "        nfold=5,\n",
        "        metrics=['mae'],\n",
        "        early_stopping_rounds=10\n",
        "        )\n",
        "    mean_mae = cv_results['test-mae-mean'].min()\n",
        "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
        "    print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\n",
        "    if mean_mae < min_mae:\n",
        "        min_mae = mean_mae\n",
        "        best_params = eta\n",
        "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kp1fstln1cIt"
      },
      "outputs": [],
      "source": [
        "params['eta'] = .05\n",
        "\n",
        "model = xgb.train(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=num_boost_round,\n",
        "    evals=[(dtest, \"Test\")],\n",
        "    early_stopping_rounds=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN_98lI83Ogr",
        "outputId": "1eb0ea7e-629a-4000-fff9-4d6714d8ca5e"
      },
      "outputs": [],
      "source": [
        "num_boost_round = model.best_iteration + 1\n",
        "best_model = xgb.train(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=num_boost_round,\n",
        "    evals=[(dtest, \"Test\")]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "KYwAANg1Tj8W",
        "outputId": "85308e92-15ed-4904-8021-7b9c5d23e378"
      },
      "outputs": [],
      "source": [
        "# model evaluation for testing set\n",
        "mae = mean_absolute_error(y_test, best_model.predict(dtest))\n",
        "mse = mean_squared_error(y_test, best_model.predict(dtest))\n",
        "rmse = math.sqrt(mean_squared_error(y_test, best_model.predict(dtest)))\n",
        "r2 = r2_score(y_test, best_model.predict(dtest))\n",
        "\n",
        "print(\"The model performance for testing set\")\n",
        "print(\"--------------------------------------\")\n",
        "print('MAE:  {}'.format(round(mae)))\n",
        "print('MSE:  {}'.format(round(mse)))\n",
        "print('RMSE: {}'.format(round(rmse)))\n",
        "print('R2:   {}'.format(round(r2, 3)))\n",
        "df = pd.DataFrame({'Actual': y_test, 'Predicted': best_model.predict(dtest)})\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hq4TZd22YMvx"
      },
      "source": [
        "### Working with HyperOpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# XGB parameters\n",
        "xgb_reg_params = {\n",
        "    'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
        "    'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
        "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
        "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
        "    'subsample':        hp.uniform('subsample', 0.8, 1),\n",
        "    'n_estimators':     100,\n",
        "}\n",
        "xgb_fit_params = {\n",
        "    'eval_metric': 'rmse',\n",
        "    'early_stopping_rounds': 10,\n",
        "    'verbose': False\n",
        "}\n",
        "xgb_para = dict()\n",
        "xgb_para['reg_params'] = xgb_reg_params\n",
        "xgb_para['fit_params'] = xgb_fit_params\n",
        "xgb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LightGBM parameters\n",
        "lgb_reg_params = {\n",
        "    'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
        "    'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
        "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
        "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
        "    'subsample':        hp.uniform('subsample', 0.8, 1),\n",
        "    'n_estimators':     100,\n",
        "}\n",
        "lgb_fit_params = {\n",
        "    'eval_metric': 'l2',\n",
        "    'early_stopping_rounds': 10,\n",
        "    'verbose': False\n",
        "}\n",
        "lgb_para = dict()\n",
        "lgb_para['reg_params'] = lgb_reg_params\n",
        "lgb_para['fit_params'] = lgb_fit_params\n",
        "lgb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUrzaViAWEUa"
      },
      "outputs": [],
      "source": [
        "# CatBoost parameters\n",
        "ctb_reg_params = {\n",
        "    'learning_rate':     hp.choice('learning_rate',     np.arange(0.05, 0.31, 0.05)),\n",
        "    'max_depth':         hp.choice('max_depth',         np.arange(5, 16, 1, dtype=int)),\n",
        "    'colsample_bylevel': hp.choice('colsample_bylevel', np.arange(0.3, 0.8, 0.1)),\n",
        "    'n_estimators':      100,\n",
        "    'eval_metric':       'RMSE',\n",
        "}\n",
        "ctb_fit_params = {\n",
        "    'early_stopping_rounds': 10,\n",
        "    'verbose': False\n",
        "}\n",
        "ctb_para = dict()\n",
        "ctb_para['reg_params'] = ctb_reg_params\n",
        "ctb_para['fit_params'] = ctb_fit_params\n",
        "ctb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0PTYXN8YLb7"
      },
      "outputs": [],
      "source": [
        "class HPOpt(object):\n",
        "\n",
        "    def __init__(self, x_train, x_test, y_train, y_test):\n",
        "        self.x_train = x_train\n",
        "        self.x_test  = x_test\n",
        "        self.y_train = y_train\n",
        "        self.y_test  = y_test\n",
        "\n",
        "    def process(self, fn_name, space, trials, algo, max_evals):\n",
        "        fn = getattr(self, fn_name)\n",
        "        try:\n",
        "            result = fmin(fn=fn, space=space, algo=algo, max_evals=max_evals, trials=trials)\n",
        "        except Exception as e:\n",
        "            return {'status': STATUS_FAIL,\n",
        "                    'exception': str(e)}\n",
        "        return result, trials\n",
        "\n",
        "    def xgb_reg(self, para):\n",
        "        reg = xgb.XGBRegressor(**para['reg_params'])\n",
        "        return self.train_reg(reg, para)\n",
        "\n",
        "    def lgb_reg(self, para):\n",
        "        reg = lgb.LGBMRegressor(**para['reg_params'])\n",
        "        return self.train_reg(reg, para)\n",
        "\n",
        "    def ctb_reg(self, para):\n",
        "        reg = ctb.CatBoostRegressor(**para['reg_params'])\n",
        "        return self.train_reg(reg, para)\n",
        "\n",
        "    def train_reg(self, reg, para):\n",
        "        reg.fit(self.x_train, self.y_train,\n",
        "                eval_set=[(self.x_train, self.y_train), (self.x_test, self.y_test)],\n",
        "                **para['fit_params'])\n",
        "        pred = reg.predict(self.x_test)\n",
        "        loss = para['loss_func'](self.y_test, pred)\n",
        "        return {'loss': loss, 'status': STATUS_OK}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbmYwiG7Z4gL",
        "outputId": "4d9eec7e-1bfd-4a8b-dc22-7e3a47ab6f1a"
      },
      "outputs": [],
      "source": [
        "obj = HPOpt(X_train, X_test, y_train, y_test)\n",
        "\n",
        "xgb_opt = obj.process(fn_name='xgb_reg', space=xgb_para, trials=Trials(), algo=tpe.suggest, max_evals=100)\n",
        "lgb_opt = obj.process(fn_name='lgb_reg', space=lgb_para, trials=Trials(), algo=tpe.suggest, max_evals=100)\n",
        "ctb_opt = obj.process(fn_name='ctb_reg', space=ctb_para, trials=Trials(), algo=tpe.suggest, max_evals=100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Regression_AirBnB_pricing_predict_04092022.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "0722c8c7dc47d291528b2dd33cc68e07219c9276365983109bfa0a474f63df76"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
